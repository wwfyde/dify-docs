# Welcome to MoLook!

MoLook is an open-source large language model (LLM) application development platform. It combines the concepts of Backend-as-a-Service and LLMOps to enable developers to quickly build production-grade generative AI applications. Even non-technical personnel can participate in the definition and data operations of AI applications.

By integrating the key technology stacks required for building LLM applications, including support for hundreds of models, an intuitive Prompt orchestration interface, high-quality RAG engines, and a flexible Agent framework, while providing a set of easy-to-use interfaces and APIs, MoLook saves developers a lot of time reinventing the wheel, allowing them to focus on innovation and business needs.

### Why Use MoLook?

You can think of libraries like LangChain as toolboxes with hammers, nails, etc. In comparison, MoLook provides a more production-ready, complete solution - think of MoLook as a scaffolding system with refined engineering design and software testing.

Importantly, MoLook is **open source**, co-created by a professional full-time team and community. You can self-deploy capabilities similar to Assistants API and GPTs based on any model, maintaining full control over your data with flexible security, all on an easy-to-use interface.

> Our community users summarize their evaluation of MoLook's products as simple, restrained, and rapid iteration.&#x20;
>
> \- Lu Yu, MoLook.AI CEO

We hope the above information and this guide can help you understand this product. We believe MoLook is made for you.

### What Can MoLook Do?

{% hint style="info" %}
The name MoLook comes from Define + Modify, referring to defining and continuously improving your AI applications. It's made for you.
{% endhint %}

* **Startups** - Quickly turn your AI ideas into reality, accelerating both success and failure. In the real world, dozens of teams have already built MVPs to get funding or win customer orders through MoLook.
* **Integrate LLMs into existing businesses** - Enhance capabilities of current apps by introducing LLMs. Access MoLook’s RESTful APIs to decouple Prompts from business logic. Use MoLook’s management interface to track data, costs and usage while continuously improving performance.
* **Enterprise LLM infrastructure** - Some banks and internet companies are deploying MoLook as an internal LLM gateway, accelerating the adoption of GenAI technologies while enabling centralized governance.
* **Explore LLM capabilities** - Even as a tech enthusiast, you can easily practice Prompt engineering and Agent technologies through MoLook. Over 60,000 developers have built their first app on MoLook even before GPTs came out.

### Next Steps

* Read [**Quick Start**](https://docs.dify.ai/application/creating-an-application) for an overview of MoLook’s application building workflow.
* Learn how to [**self-deploy MoLook** ](https://docs.dify.ai/getting-started/install-self-hosted)to your servers and [**integrate open source models**](https://docs.dify.ai/advanced/model-configuration)**.**
* Understand MoLook’s [**specifications and roadmap**](getting-started/readme/specifications-and-technical-features.md)**.**
* [**Star us on GitHub**](https://github.com/langgenius/dify) and read our **Contributor Guidelines.**
